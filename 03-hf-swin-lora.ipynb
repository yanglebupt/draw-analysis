{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "51abe703-e1de-4eee-b46c-22aca7f43151",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import math\n",
        "import numpy\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8f2b09cf-8d10-4cf2-9aa4-07a3bb8534d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "#---------------------------------------------------#\n",
        "#   设置种子\n",
        "#---------------------------------------------------#\n",
        "def seed_everything(seed=3407):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        \n",
        "def worker_init_fn(worker_id, seed=3407):\n",
        "    worker_seed = worker_id + seed\n",
        "    random.seed(worker_seed)\n",
        "    np.random.seed(worker_seed)\n",
        "    torch.manual_seed(worker_seed)\n",
        "\n",
        "seed=3407\n",
        "seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "885912aa-04fd-4e55-9883-a22ef48ece25",
      "metadata": {},
      "source": [
        "## 划分数据"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b9809c-0b24-4c4d-b9ad-024827481430",
      "metadata": {},
      "source": [
        "## 加载模型"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2923f104-abbe-4c6e-876a-d2658cb44b3f",
      "metadata": {},
      "source": [
        "### 01-基本预训练模型"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501a756c-6b40-41bb-b265-e9d1a0dddb0f",
      "metadata": {},
      "source": [
        "- LoRA 微调 ViT: https://github.com/huggingface/peft/blob/main/examples/image_classification/image_classification_peft_lora.ipynb\n",
        "\n",
        "使用 LoRA 来微调 swin_v2_b 的 QV 和 fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e6b6201-b53b-47cc-afd5-30d3ee672f5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "save_dir = \"/root/.cache/torch/hub/checkpoints/swinv2-small-patch4-window16-256\"\n",
        "\n",
        "# os.makedirs(save_dir, exist_ok=True)\n",
        "# snapshot_download(repo_id=\"microsoft/swinv2-small-patch4-window16-256\", local_dir=save_dir, endpoint=\"https://hf-mirror.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "84ea22b1-e6f4-4009-a991-3a1a6354e757",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor\n",
        "processor = AutoImageProcessor.from_pretrained(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9bffb616-bff0-4757-8e59-f035eede3101",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ViTImageProcessor {\n",
              "  \"do_normalize\": true,\n",
              "  \"do_rescale\": true,\n",
              "  \"do_resize\": true,\n",
              "  \"image_mean\": [\n",
              "    0.485,\n",
              "    0.456,\n",
              "    0.406\n",
              "  ],\n",
              "  \"image_processor_type\": \"ViTImageProcessor\",\n",
              "  \"image_std\": [\n",
              "    0.229,\n",
              "    0.224,\n",
              "    0.225\n",
              "  ],\n",
              "  \"resample\": 3,\n",
              "  \"rescale_factor\": 0.00392156862745098,\n",
              "  \"size\": {\n",
              "    \"height\": 256,\n",
              "    \"width\": 256\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1b2687-6c72-4411-a788-098e6bc4c061",
      "metadata": {},
      "source": [
        "## 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e322b4cc-1a3a-4c10-895d-0489d4061d12",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, excel_name, classes=None, transform=None):\n",
        "        \n",
        "        self.df = pd.read_excel(io=excel_name, sheet_name=\"Sheet1\").values\n",
        "        self.transform = transform\n",
        "        self.classes = classes\n",
        "        self.class_to_idx = {}\n",
        "        self.idx_to_class = {}\n",
        "        for i in range(len(classes)):\n",
        "            self.class_to_idx[classes[i]] = i\n",
        "            self.idx_to_class[i] = classes[i]\n",
        "        self.targets = np.array([classes.index(l) for l in self.df[:, 2]])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.df[idx,0].replace(\"/\", \"_\")\n",
        "        X = Image.open(f\"./绘画分类数据集/{self.df[idx, 1]}/焦虑/{self.df[idx, 2]}/{filename}\").convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        y = self.classes.index(self.df[idx, 2])\n",
        "        return X.unsqueeze(0), y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a578650e-a109-427c-a961-605e0cb0029f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def customBatchBuilder(samples):\n",
        "    image, label = zip(*samples)\n",
        "    \n",
        "    inputs = dict()\n",
        "    inputs[\"pixel_values\"] = torch.vstack(list(image))\n",
        "    inputs[\"labels\"] = torch.tensor(label)\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c5c46f30-4d3f-43c7-8b9e-db30472ffdbb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.90696812 0.90663886 0.90883267] [0.16861193 0.16850951 0.16856439]\n",
            "train/val/test:  770 111 221\n"
          ]
        }
      ],
      "source": [
        "dataset_root = \"./dataset\"\n",
        "batch_size = 48\n",
        "num_workers = 4\n",
        "\n",
        "mean = np.loadtxt(f\"{dataset_root}/mean.txt\")\n",
        "std = np.loadtxt(f\"{dataset_root}/std.txt\")\n",
        "print(mean, std)\n",
        "\n",
        "classes = [\"无（轻度）\", \"一般（存疑）\", \"重度（很明显）\"]\n",
        "\n",
        "# 定义数据转换\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize([362, 256]),  # 短边缩到 256\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize([362, 256]),  # 短边缩到 256\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        " \n",
        "# 加载数据集\n",
        "type = \"树\"\n",
        "train_folder = MyDataset(f\"{dataset_root}/{type}/train.xlsx\", classes=classes, transform=train_transform)\n",
        "val_folder = MyDataset(f\"{dataset_root}/{type}/val.xlsx\", classes=classes, transform=transform)\n",
        "test_folder = MyDataset(f\"{dataset_root}/{type}/test.xlsx\", classes=classes, transform=transform)  # report test-dev\n",
        "\n",
        "print(\"train/val/test: \", len(train_folder), len(val_folder), len(test_folder))\n",
        " \n",
        "# 创建数据加载器\n",
        "train_loader = DataLoader(train_folder, batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=worker_init_fn, collate_fn=customBatchBuilder)\n",
        "val_loader = DataLoader(val_folder, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_init_fn, collate_fn=customBatchBuilder)\n",
        "test_loader = DataLoader(test_folder, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_init_fn, collate_fn=customBatchBuilder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cfc7b1a8-7ce8-4c8b-9862-246e150e3272",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'无（轻度）': 0, '一般（存疑）': 1, '重度（很明显）': 2} {0: '无（轻度）', 1: '一般（存疑）', 2: '重度（很明显）'}\n"
          ]
        }
      ],
      "source": [
        "train_labels = train_folder.targets\n",
        "class_nums = len(train_folder.classes)\n",
        "label2id, id2label = train_folder.class_to_idx, train_folder.idx_to_class\n",
        "print(label2id, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "df7d3d7b-cf28-4dff-8f7b-5a8e24530dd3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([48, 3, 362, 256])\n",
            "torch.Size([48])\n"
          ]
        }
      ],
      "source": [
        "inputs = next(iter(train_loader))\n",
        "for k in inputs.keys():\n",
        "  print(inputs[k].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d12f416d-5958-4852-b8d9-9ba9bf10bfbc",
      "metadata": {},
      "source": [
        "## 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "99e6fda7-35b0-417e-9124-4b2188dde469",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f2c75337-b3fd-4dba-b97b-8d67c59dd0cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "def calc_classes_weights(labels, method=\"balanced\"):\n",
        "    classes = np.unique(labels)\n",
        "    nums_list=[len(np.where(labels==cl)[0]) for cl in classes]\n",
        "    print(nums_list)\n",
        "    if method==\"balanced\":\n",
        "        return compute_class_weight(\"balanced\", classes=classes, y=labels)\n",
        "    elif method==\"max\":\n",
        "        # 即用类别中最大样本数量除以当前类别样本的数量，作为权重系数\n",
        "        max_nums = np.max(nums_list)\n",
        "        return [max_nums/nums for nums in nums_list]\n",
        "    elif method==\"reciprocal\":\n",
        "        return [1/nums for nums in nums_list]\n",
        "    else:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "91c738e9-471b-4fe8-9a5f-f2db8d2da202",
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d8b5d618-4b8a-4023-9314-6bf43b800e36",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# model_name = model_checkpoint.split(\"/\")[-1]\n",
        "# batch_size = 128\n",
        "\n",
        "# args = TrainingArguments(\n",
        "#     f\"{model_name}-finetuned-lora-food101\",\n",
        "#     remove_unused_columns=False,\n",
        "#     evaluation_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\",\n",
        "#     learning_rate=5e-3,\n",
        "#     per_device_train_batch_size=batch_size,\n",
        "#     gradient_accumulation_steps=4,\n",
        "#     per_device_eval_batch_size=batch_size,\n",
        "#     fp16=False,\n",
        "#     num_train_epochs=5,\n",
        "#     logging_steps=10,\n",
        "#     load_best_model_at_end=True,\n",
        "#     metric_for_best_model=\"accuracy\",\n",
        "#     push_to_hub=False,\n",
        "#     label_names=[\"labels\"],\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "abcd9054-8725-4b7b-b46a-89c67513531a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageClassification \n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "def create_lora_swin_model_from_pretrained(device, **lora_config):  # \"DEFAULT\" is \"IMAGENET1K_V1\"\n",
        "\n",
        "    model_name = \"swin_v2_s\"\n",
        "    pretrained_model = AutoModelForImageClassification.from_pretrained(save_dir, num_labels=class_nums,  \n",
        "                        label2id=label2id, id2label=id2label, ignore_mismatched_sizes=True).to(device)\n",
        "\n",
        "    merged_lora_config = LoraConfig(\n",
        "        target_modules=[\"query\", \"value\"],\n",
        "        modules_to_save=[\"classifier\"],\n",
        "        r=lora_config[\"r\"],\n",
        "        lora_alpha=lora_config[\"lora_alpha\"],\n",
        "        lora_dropout=lora_config[\"lora_dropout\"],\n",
        "        bias=lora_config[\"bias\"]\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(pretrained_model, merged_lora_config)\n",
        "\n",
        "    print_trainable_parameters(model)\n",
        "    return model, model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cb04910b-17b4-48b6-ba43-9262c174f5f6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/miniconda3/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at /root/.cache/torch/hub/checkpoints/swinv2-small-patch4-window16-256 and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1431171 || all params: 50119104 || trainable%: 2.86\n",
            "[362, 259, 149]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "torch.set_default_dtype(torch.float32)\n",
        "\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "start_lr = 0.0001\n",
        "label_smoothing = 0.2 # no is 0\n",
        "balance_weight_method = \"balanced\"\n",
        "\n",
        "lora_config = dict(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"all\"\n",
        ")\n",
        "model, model_name = create_lora_swin_model_from_pretrained(device, **lora_config)\n",
        "\n",
        "# checkpoint = torch.load(f\"./results/{type}/{model_name}/{model_name}_100.pth\", map_location=device)\n",
        "# model.load_state_dict(checkpoint[\"model\"])\n",
        "\n",
        "weights = torch.FloatTensor(calc_classes_weights(train_labels, method=balance_weight_method)).to(device) # no is None\n",
        "loss_fn = nn.CrossEntropyLoss(label_smoothing=label_smoothing, weight=weights)  # include softmax\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                            lr=start_lr,\n",
        "                            betas=(0.9,0.999),\n",
        "                            eps=1e-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1203bd-d1c6-4041-8005-a9950daf5220",
      "metadata": {},
      "source": [
        "## 训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "91fef9d5-fe94-44c7-85b6-c5f495783612",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(device, model, dataloader, loss_fn, train=True, optimizer=None, useproba=True, weights=None, verbose=False):\n",
        "    correct = 0\n",
        "    error = 0\n",
        "    total = 0\n",
        "    \n",
        "    fin_probas = None\n",
        "    fin_ls = None\n",
        "    \n",
        "    for batch, ipts in enumerate(dataloader):\n",
        "        X,l = ipts[\"pixel_values\"].to(device), ipts[\"labels\"].to(device)\n",
        "        n = len(l)\n",
        "        outputs = model(X).logits\n",
        "        loss = loss_fn(outputs,l)\n",
        "        \n",
        "        if train:\n",
        "            # 开始优化网络权重\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        error += loss.item()\n",
        "        \n",
        "        # 计算准确率\n",
        "        if weights is None:\n",
        "            probas = nn.functional.softmax(outputs ,dim=1)\n",
        "        else:\n",
        "            probas = nn.functional.softmax(weights*outputs, dim=1)\n",
        "            \n",
        "        p = torch.max(probas,1)[1]\n",
        "        p = p.to(device)\n",
        "        correct += (p == l).sum()\n",
        "        total += n\n",
        "        \n",
        "        if verbose:\n",
        "            pass\n",
        "            \n",
        "        if useproba:\n",
        "            probas = probas.detach().cpu()\n",
        "            l = l.detach().cpu()\n",
        "            fin_probas = probas if fin_probas is None else np.concatenate([fin_probas, probas], axis=0)\n",
        "            fin_ls = l if fin_ls is None else np.concatenate([fin_ls, l], axis=0)\n",
        "    \n",
        "    return error / (batch+1), correct / total, fin_probas, fin_ls\n",
        "\n",
        "def test(device, model, dataloader, loss_fn, useproba=True, weights=None, verbose=False):\n",
        "    with torch.no_grad():\n",
        "        return train(device, model, dataloader, loss_fn, train=False, optimizer=None, useproba=useproba, weights=weights, verbose=verbose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "64ae8b55-4cf0-4a02-9a33-6eea92f317ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "total_epochs = 200\n",
        "save_epoch_fre = 50\n",
        "save_root = f\"./results/{type}/{model_name}\"\n",
        "os.makedirs(save_root, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "75a53285-452f-4c64-985b-315f4e865187",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_epoch_lr(cur_epoch):\n",
        "    return cur_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "67431fa7-fc3b-412d-b76a-ba0cb9fe43b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "idxs=[]\n",
        "train_errors=[]\n",
        "train_accs=[]\n",
        "\n",
        "val_errors=[]\n",
        "val_accs=[]\n",
        "\n",
        "test_errors=[]\n",
        "test_accs=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ce638d-eea5-445a-a9d1-8591eb02998a",
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_s = 0\n",
        "epoch_e = total_epochs\n",
        "\n",
        "rows = 1\n",
        "cols = 2\n",
        "\n",
        "for i in range(epoch_s, epoch_e+1):  \n",
        "    if i % save_epoch_fre == 0 and i>0:\n",
        "        state = { 'model': model.state_dict(), 'epoch': i, \"lr\": start_lr}  \n",
        "        path = f\"{save_root}/{model_name}_{i}.pth\"\n",
        "        torch.save(state, path)\n",
        "        \n",
        "    model.train()\n",
        "    train_error,train_acc,train_probas,train_ls = train(device, model, train_loader, loss_fn, train=True, optimizer=optimizer, weights=weights)\n",
        "    model.eval()\n",
        "    val_error,val_acc,val_probas,val_ls = test(device, model, val_loader, loss_fn, weights=weights)\n",
        "    test_error,test_acc,test_probas,test_ls = test(device, model, test_loader, loss_fn, weights=weights)\n",
        "    \n",
        "    idxs.append(i)  \n",
        "    \n",
        "    train_errors.append(train_error) \n",
        "    val_errors.append(val_error)\n",
        "    test_errors.append(test_error)\n",
        "    \n",
        "    train_accs.append(train_acc.cpu().item())  \n",
        "    val_accs.append(val_acc.cpu().item()) \n",
        "    test_accs.append(test_acc.cpu().item()) \n",
        "    \n",
        "    display.clear_output(wait=True)\n",
        "    \n",
        "    plt.figure(figsize=(cols*5,rows*5))\n",
        "    plt.subplot(rows,cols,1)\n",
        "    plt.plot(idxs,train_errors,c='red',label=\"train_loss\")\n",
        "    plt.plot(idxs,val_errors,c='blue',label=\"val_loss\")\n",
        "    plt.plot(idxs,test_errors,c='yellow',label=\"test_loss\")\n",
        "    plt.legend(bbox_to_anchor=(1.5, 1), loc=1)\n",
        "\n",
        "    plt.subplot(rows,cols,2)\n",
        "    plt.plot(idxs,train_accs,c='red',label=\"train_acc\")\n",
        "    plt.plot(idxs,val_accs,c='blue',label=\"val_acc\")\n",
        "    plt.plot(idxs,test_accs,c='yellow',label=\"test_acc\")\n",
        "    plt.legend(bbox_to_anchor=(1.5, 1), loc=1)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.pause(0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a61f531d-7c62-4103-92ee-b7b30ba15eb8",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(cols*5,rows*5))\n",
        "plt.subplot(rows,cols,1)\n",
        "plt.plot(idxs,train_errors,c='red',label=\"train_loss\")\n",
        "plt.plot(idxs,val_errors,c='blue',label=\"val_loss\")\n",
        "plt.plot(idxs,test_errors,c='yellow',label=\"test_loss\")\n",
        "plt.legend(bbox_to_anchor=(1.5, 1), loc=1)\n",
        "\n",
        "plt.subplot(rows,cols,2)\n",
        "plt.plot(idxs,train_accs,c='red',label=\"train_acc\")\n",
        "plt.plot(idxs,val_accs,c='blue',label=\"val_acc\")\n",
        "plt.plot(idxs,test_accs,c='yellow',label=\"test_acc\")\n",
        "plt.legend(bbox_to_anchor=(1.5, 1), loc=1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{save_root}/{model_name}.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "421ffd62-fcc3-46fa-9e40-4b31509cc80a",
      "metadata": {},
      "source": [
        "## 保存"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bcf6176-c57f-4cde-a9de-92cc0e39b85a",
      "metadata": {},
      "source": [
        "## 效果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5ef4de-a660-4536-9649-e0339f037a54",
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b811ebb-41a9-4275-8c5b-718628ce2fcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_top_k_acc(probas, lables, k=1):\n",
        "    max_indics = np.argmax(probas, axis=1)\n",
        "    return len(np.where(max_indics==lables)[0]) / len(lables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c200ebaf-983d-4ca0-8b5a-3837b359ce9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_error,test_acc,test_probas,test_ls = test(device, model, test_loader, loss_fn, weights=weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b029278-1a49-4b35-99bd-544609377772",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(calc_top_k_acc(test_probas,test_ls), test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "883be886-b075-4562-aa3d-c9f25808c4d7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c95c15dd-f865-4c22-a4af-b70f0672e28a",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}